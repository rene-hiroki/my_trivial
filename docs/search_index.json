[
["index.html", "日々の雑学 はじめに 0.1 環境", " 日々の雑学 Akiyama Hiroki 最終更新日: 2020-06-29 はじめに 作成中です hogehoge fugafuga 0.1 環境 sessionInfo() R version 3.6.3 (2020-02-29) Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64 (build 18363) Matrix products: default locale: [1] LC_COLLATE=Japanese_Japan.932 LC_CTYPE=Japanese_Japan.932 LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C [5] LC_TIME=Japanese_Japan.932 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] plotly_4.9.2.1 stringi_1.4.6 leaflet_2.0.3 ggmap_3.0.0 DT_0.14 lubridate_1.7.9 jsonlite_1.7.0 bookdown_0.20 [9] here_0.1 ggrepel_0.8.2 naniar_0.5.1 patchwork_1.0.1 NbClust_3.0 factoextra_1.0.7 yardstick_0.0.6 workflows_0.1.1 [17] tune_0.1.0 rsample_0.0.7 recipes_0.1.13 parsnip_0.1.1 infer_0.5.2 dials_0.0.7 scales_1.1.1 broom_0.5.6 [25] tidymodels_0.1.0 forcats_0.5.0 stringr_1.4.0 dplyr_1.0.0 purrr_0.3.4 readr_1.3.1 tidyr_1.1.0 tibble_3.0.1 [33] ggplot2_3.3.2 tidyverse_1.3.0 loaded via a namespace (and not attached): [1] pacman_0.5.1 utf8_1.1.4 tidyselect_1.1.0 lme4_1.1-23 htmlwidgets_1.5.1 grid_3.6.3 [7] pROC_1.16.2 munsell_0.5.0 codetools_0.2-16 statmod_1.4.34 future_1.17.0 miniUI_0.1.1.1 [13] withr_2.2.0 colorspace_1.4-1 knitr_1.29 rstudioapi_0.11 stats4_3.6.3 ggsignif_0.6.0 [19] bayesplot_1.7.2 listenv_0.8.0 labeling_0.3 rstan_2.19.3 RgoogleMaps_1.4.5.3 DiceDesign_1.8-1 [25] farver_2.0.3 rprojroot_1.3-2 vctrs_0.3.1 generics_0.0.2 ipred_0.9-9 xfun_0.15 [31] R6_2.4.1 markdown_1.1 rstanarm_2.19.3 bitops_1.0-6 lhs_1.0.2 assertthat_0.2.1 [37] promises_1.1.1 nnet_7.3-14 gtable_0.3.0 globals_0.12.5 processx_3.4.2 timeDate_3043.102 [43] rlang_0.4.6 splines_3.6.3 rstatix_0.6.0 lazyeval_0.2.2 inline_0.3.15 abind_1.4-5 [49] yaml_2.2.1 reshape2_1.4.4 modelr_0.1.8 tidytext_0.2.4 threejs_0.3.3 crosstalk_1.1.0.1 [55] backports_1.1.8 httpuv_1.5.4 rsconnect_0.8.16 tokenizers_0.2.1 tools_3.6.3 lava_1.6.7 [61] ellipsis_0.3.1 ggridges_0.5.2 Rcpp_1.0.4.6 plyr_1.8.6 base64enc_0.1-3 ps_1.3.3 [67] prettyunits_1.1.1 ggpubr_0.4.0 rpart_4.1-15 zoo_1.8-8 cluster_2.1.0 haven_2.3.1 [73] fs_1.4.1 furrr_0.1.0 magrittr_1.5 data.table_1.12.8 openxlsx_4.1.5 colourpicker_1.0 [79] reprex_0.3.0 GPfit_1.0-8 SnowballC_0.7.0 packrat_0.5.0 matrixStats_0.56.0 tidyposterior_0.0.3 [85] hms_0.5.3 shinyjs_1.1 mime_0.9 evaluate_0.14 xtable_1.8-4 tidypredict_0.4.5 [91] shinystan_2.5.0 jpeg_0.1-8.1 rio_0.5.16 readxl_1.3.1 gridExtra_2.3 rstantools_2.0.0 [97] compiler_3.6.3 crayon_1.3.4 minqa_1.2.4 StanHeaders_2.21.0-5 htmltools_0.5.0 later_1.1.0.1 [103] visdat_0.5.3 RcppParallel_5.0.2 DBI_1.1.0 dbplyr_1.4.4 MASS_7.3-51.6 boot_1.3-25 [109] Matrix_1.2-18 car_3.0-8 cli_2.0.2 parallel_3.6.3 gower_0.2.2 igraph_1.2.5 [115] pkgconfig_2.0.3 sp_1.4-2 foreign_0.8-76 xml2_1.3.2 foreach_1.5.0 dygraphs_1.1.1.6 [121] prodlim_2019.11.13 rvest_0.3.5 janeaustenr_0.1.5 callr_3.4.3 digest_0.6.25 rmarkdown_2.3 [127] cellranger_1.1.0 curl_4.3 shiny_1.5.0 gtools_3.8.2 rjson_0.2.20 nloptr_1.2.2.1 [133] lifecycle_0.2.0 nlme_3.1-148 carData_3.0-4 viridisLite_0.3.0 fansi_0.4.1 pillar_1.4.4 [139] lattice_0.20-41 loo_2.2.0 fastmap_1.0.1 httr_1.4.1 pkgbuild_1.0.8 survival_3.2-3 [145] glue_1.4.1 xts_0.12-0 zip_2.0.4 png_0.1-7 shinythemes_1.1.2 iterators_1.0.12 [151] class_7.3-17 blob_1.2.1 "],
["01_android_analysis.html", "Chapter: 1 android分析 1.1 ライブラリの準備 1.2 activityをダウンロード 1.3 ここから解析", " Chapter: 1 android分析 1.1 ライブラリの準備 pacman::p_loadを使うと、ライブラリをまとめて読み込んでくれます。また、インストールされていないライブラリがある場合は、インストールかつ読み込みを行ってくれます。 pacmanがインストールされていない場合は、コメントアウトしてインストールしてください。 # install.packages(pacman) pacman::p_load(tidyverse, jsonlite, patchwork, here, lubridate, update = FALSE) 1.2 activityをダウンロード あとで書く google takeout で検索 1.3 ここから解析 1.3.1 activityの読み込み android &lt;- jsonlite::fromJSON(here(&quot;data/android_activity.json&quot;)) 1.3.2 読み込んだactivityデータの概要確認 glimpse(android) Rows: 63,120 Columns: 5 $ header [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;びよーんったー Pro&quot;, &quot;Nova Launcher ホーム&quot;, &quot;Gmail&quot;, &quot;Slack&quot;, &quot;Nova Launcher ホーム&quot;, &quot;com.android.systemui&quot;, &quot;LINE（ライン） - 無料通話・メ... $ title [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;使用: びよーんったー Pro&quot;, &quot;使用: Nova Launcher ホーム&quot;, &quot;使用: Gmail&quot;, &quot;使用: Slack&quot;, &quot;使用: Nova Launcher ホーム&quot;, &quot;使用: com.android.system... $ titleUrl [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;https://play.google.com/store/apps/details?id=com.ABS104a.biyontterpro&quot;, &quot;https://play.google.com/store/apps/details?... $ time [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;2020-04-16T21:29:57.048Z&quot;, &quot;2020-04-16T21:29:54.832Z&quot;, &quot;2020-04-16T21:29:28.111Z&quot;, &quot;2020-04-16T21:27:42.460Z&quot;, &quot;2020-... $ products [3m[38;5;246m&lt;list&gt;[39m[23m [&quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Andro... 1.3.3 timeデータを変換 android &lt;- android %&gt;% mutate(time = parse_datetime(time, locale = locale(tz = &quot;Japan&quot;)) ) %&gt;% mutate(date = lubridate::date(time), year = lubridate::year(time)) 1.3.4 年月ごとのデータ数の集計 2018年8月以前のデータが少ない。 activityデータの収集がうまくいっていなかった？ android %&gt;% group_by(year, month(date)) %&gt;% count() # A tibble: 37 x 3 # Groups: year, month(date) [37] year `month(date)` n &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 2016 12 2 2 2017 1 1 3 2017 2 56 4 2017 3 26 5 2017 5 6 6 2017 6 64 7 2017 7 12 8 2017 8 29 9 2017 9 32 10 2017 11 4 # ... with 27 more rows android %&gt;% count(date) %&gt;% ggplot() + geom_line(aes(date,n)) + scale_x_date(breaks = &quot;month&quot;, guide = guide_axis(n.dodge = 3)) 1.3.5 データの準備 2019年と2020年のデータのみを使うことにする。 android_latest &lt;- android %&gt;% filter(year %in% c(2019, 2020)) アプリの名前が長いから20文字までにする。 android_latest &lt;- android_latest %&gt;% mutate(header = if_else(str_length(header) &gt;= 20, substr(header, 1, 20), header)) android &lt;- android %&gt;% mutate(header = if_else(str_length(header) &gt;= 20, substr(header, 1, 20), header)) 1.3.6 アプリの使用回数（2019-2020） android_latest %&gt;% count(header, sort = TRUE) %&gt;% head(5) %&gt;% mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + theme_minimal() + labs(title = &quot;Most used Apps - Overall&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) 1.3.7 アプリの使用回数（すべての年） android %&gt;% count(header, sort = TRUE) %&gt;% head(5) %&gt;% mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + theme_minimal() + labs(title = &quot;Most used Apps - Overall&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) 1.3.8 比較（2019 vs 2020） android_latest %&gt;% filter(year %in% &#39;2019&#39;) %&gt;% group_by(year, header) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% #View() mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + # facet_wrap(~year, scales = &quot;free&quot;) + theme_minimal() + labs(title = &quot;Most used Apps - 2019&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) -&gt; p2019 android_latest %&gt;% filter(year %in% &#39;2020&#39;) %&gt;% group_by(year, header) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% #View() mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + # facet_wrap(~year, scales = &quot;free&quot;) + theme_minimal() + labs(title = &quot;Most used Apps - 2020&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) -&gt; p2020 p2019 / p2020 "],
["02_standard_input.html", "Chapter: 2 標準入力 2.1 readLines 2.2 スクリプトで計算処理 2.3 テキストファイルを読ませる", " Chapter: 2 標準入力 標準入力、つまりはPythonで言うところのinput()をRでやろうとしたら、かなり苦労したのでtipsとしてまとめておくことにした。 2.1 readLines ずばりRで標準入力をするにはreadLinesを使う。ただし、 input_lines &lt;- readLines(&quot;stdin&quot;) このように\"stdin\"という引数を使用する。おそらくstandard input の略か何かだろう。 注意すべきは、このコードをRのコンソールで実行してしまうとRがうんともすんとも言わなくなってしまうこと。 詳しい理由はわからないが、コマンドプロンプトからの標準入力を受けるように指示しているので、コンソールで実行してしまうとダメ、ということなのだろうか（誰か教えて欲しい）。 コンソール上で実験的にコードを試したい場合は、readline()を使えばコンソールで入力待ち状態となるので、こちらを使用する。 たとえばstdin.Rに下記のように記述しておき、 #! /usr/bin/env Rscript input_lines &lt;- readLines(&quot;stdin&quot;) cat(input_lines[1]) # catは標準出力 コマンドプロンプトから下記のようにしてstdin.Rを実行してみる Rscript stdin.R すると入力待ち状態になるので、何かしら記述する。 Hello world! そして、ctrl + cあるいはctrl + zの後にEnterで入力を終了すると（他の方法ありますか？） Hello world! とプロンプトに標準出力ができる。 2.2 スクリプトで計算処理 stdin.Rに以下のように記述しておけば、標準入力で受け取った値を、計算処理をしてから返すこともできる。 #! /usr/bin/env Rscript # ライブラリもつかえる library(tidyverse) input_lines &lt;- readLines(&quot;stdin&quot;) x = as.integer(input_lines[1]) # 1つめ（1行目の入力） y = as.integer(input_lines[2]) # 2つめ cat(x + y) 2.3 テキストファイルを読ませる read_text.txtを別に以下のように準備しておき、 （read_text.txtの最終行には改行を入れないと、あとでwarningが出るので注意する。） Hello world! stdin.Rをこうしておく #! /usr/bin/env Rscript input_lines &lt;- readLines(&quot;stdin&quot;) x = input_lines[1] y = input_lines[2] cat(x, y) そしてコマンドプロンプトで次のようにすれば、read_text.txtから標準入力を受け取ることができる。 Rscript stdin.R &lt; read_text.txt プロンプトの出力はこうなる Hello world! これでatcoderにも参戦できる！ （atcoderでRは使用不可、、、） "],
["03_ido_keido.html", "Chapter: 3 緯度経度からちょっとインタラクティブな地図作成 3.1 ライブラリ読み込み 3.2 データ準備 3.3 ポップアップの文字作成 3.4 マーカーリスト 3.5 地図にプロットする 3.6 データ一覧 3.7 マーカーリスト", " Chapter: 3 緯度経度からちょっとインタラクティブな地図作成 参考にした記事 というかほぼこれ https://rpubs.com/kazutan/jssp2015_leaflet 3.1 ライブラリ読み込み library(tidyverse) library(here) library(DT) # 表作成用 library(ggmap) # 住所・緯度経度対応用 library(leaflet) # プロット用 library(stringi) # 全角から半角変換 3.2 データ準備 緯度経度取得後の想定データ # 東京ドーム 日本、〒112-0004 東京都文京区後楽１丁目３−６１ 35.7056396 139.7518913 # 福島聖天通商店街 日本、〒553-0003 大阪府大阪市福島区福島７丁目７−１２ 34.6976052 135.4846712 # 銀座通り商店街 日本、〒489-0043 愛知県瀬戸市朝日町 35.2266746 137.100508 df &lt;- tribble( ~id, ~lat, ~lon, ~address, ~group, ~name, 1, 35.7056396, 139.7518913,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;スポーツ&quot;, &quot;東京ドーム&quot;, 2, 34.6976052, 135.4846712,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;商店街A&quot; ,&quot;福島聖天通商店街&quot;, 3, 35.2266746, 137.100508,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;商店街B&quot;, &quot;銀座通り商店街&quot; ) # https://www.pediatricsurgery.site/entry/2017/10/12/105242 df &lt;- df %&gt;% mutate(address = stri_trans_nfkc(address)) # 住所の全角を半角に変換 df # A tibble: 3 x 6 id lat lon address group name &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 1 35.7 140. 〒112-0004 東京都文京区後楽1丁目3-61 スポーツ 東京ドーム 2 2 34.7 135. 〒112-0004 東京都文京区後楽1丁目3-61 商店街A 福島聖天通商店街 3 3 35.2 137. 〒112-0004 東京都文京区後楽1丁目3-61 商店街B 銀座通り商店街 3.3 ポップアップの文字作成 df &lt;- df %&gt;% mutate(popup = paste(name, group, address, sep=&quot;&lt;br/&gt;&quot;)) df # A tibble: 3 x 7 id lat lon address group name popup &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 1 35.7 140. 〒112-0004 東京都文京区後楽1丁目3-61~ スポーツ 東京ドーム 東京ドーム&lt;br/&gt;スポーツ&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61~ 2 2 34.7 135. 〒112-0004 東京都文京区後楽1丁目3-61~ 商店街A 福島聖天通商店街~ 福島聖天通商店街&lt;br/&gt;商店街A&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61~ 3 3 35.2 137. 〒112-0004 東京都文京区後楽1丁目3-61~ 商店街B 銀座通り商店街 銀座通り商店街&lt;br/&gt;商店街B&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61~ 3.4 マーカーリスト icon_df &lt;- tibble(group = df$group, icon = paste0(here(&quot;picture/icon/&quot;), &quot;/&quot;,dir(here(&quot;picture/icon/&quot;))[1:3])) icon_df # A tibble: 3 x 2 group icon &lt;chr&gt; &lt;chr&gt; 1 スポーツ C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-black.png 2 商店街A C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-blue.png 3 商店街B C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-gold.png 3.5 地図にプロットする # iconの高さと幅 w &lt;- 20 h &lt;- 30 geo &lt;- df %&gt;% leaflet() %&gt;% addTiles() for (gru in df$group){ icon_list &lt;- icons(iconUrl = icon_df %&gt;% filter(group == gru) %&gt;% pull(icon), iconWidth = w, iconHeight = h, iconAnchorX = w/2, iconAnchorY = h) geo &lt;- geo %&gt;% addMarkers(lng = ~lon, lat = ~lat, popup = ~popup, group = gru, icon = icon_list, data = dplyr::filter(.data = df, group == gru)) %&gt;% addLayersControl(overlayGroups = df$group, options = layersControlOptions(collapsed = FALSE)) } geo 3.6 データ一覧 # 一覧表示 DT::datatable(dplyr::select(df,name:group),options = list(searchHighlight = TRUE), filter = &#39;top&#39;) 3.7 マーカーリスト icon_df &lt;- tibble(group = unique(df$group), icon = paste0(here(&quot;picture/icon/&quot;), &quot;/&quot;,dir(here(&quot;picture/icon/&quot;))[1:3])) icon_df # A tibble: 3 x 2 group icon &lt;chr&gt; &lt;chr&gt; 1 スポーツ C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-black.png 2 商店街A C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-blue.png 3 商店街B C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-gold.png "],
["04_md-to-pdf.html", "Chapter: 4 pandocでmarkdownから日本語pdf出力 in vscode 4.1 目次 4.2 はじめに 4.3 目的 4.4 方法 4.5 サンプルmd 4.6 追記", " Chapter: 4 pandocでmarkdownから日本語pdf出力 in vscode 4.1 目次 はじめに 目的 方法 サンプルmd 4.2 はじめに 対象読者は、次の3つを満たしている人を想定しています。 vscodeがインストール済み Rstudioがインストール済み markdownを書いたことがある こんな感じで編集して、 こんな感じの.mdから こんな感じのpdfが出せるようになります 4.3 目的 vscodeでmarkdownを快適に編集して、日本語pdfを出力すること。 vscodeでmarkdownを編集される方は多いと思います。 なぜなら、markdownのプレビューを簡単に表示できるからです。 しかし、日本語pdfの出力がうまくいかなかったり、数式の出力ができなかったりする問題がよくあります。 その問題を解消するために、pandocを使用します。 4.4 方法 次の6つの手順を踏んで目的を達成します。 Rstudioのpandocにpathを通す vscodeの拡張機能をいろいろ追加する 簡易版TeX環境を作る ipaexフォントをインストールする front matter yamlを書く 出力のコマンド 4.4.1 Rstudioのpandocにpathを通す ココがこの記事でのキモです。 本来ならばpandocをインストールするところから始まりますが、ここではRstudioに組み込まれているpandocを使用することでインストール作業をスキップします。 Rstudioのpandocへのpathは、自分で設定する必要があります。Rstudioのpandocは、以下のようにbinの下にあります。 ~環境依存/Rstudio/bin/pandoc pathが通ったかどうかの確認として、プロンプトで次のコマンドを入力してください。 pandoc --version 以下のようにpandocのバージョンが出力されたら、pathの設定は完了です。 pandoc 2.7.2 Compiled with pandoc-types 1.17.5.4, texmath 0.11.2.2, skylighting 0.7.7 Default user data directory: C:\\Users\\AkiyamaHiroki\\AppData\\Roaming\\pandoc Copyright (C) 2006-2019 John MacFarlane Web: http://pandoc.org This is free software; see the source for copying conditions. There is no warranty, not even for merchantability or fitness for a particular purpose. 4.4.2 vscodeの拡張をいろいろ追加していく vscodeで拡張を追加する方法と、追加するいくつかの拡張について説明します。CUIで追加することもできますが、ここではGUIを使って拡張を追加します。 拡張機能リスト 拡張機能 必須/補助 内容 vscode-pandoc 必須 markdownをpandocでレンダリングするのに必要 Pandoc Markdown Preview 必須 shift + ctrl + rで、フロントマターyamlを含めたプレビューが表示できる Markdown All in One 補助 markdownの書式サポート、ほぼ必須(公式link) Markdown+Math 補助 数式のサポートいろいろ(こちらも公式linkで) 拡張機能を追加する方法 vscodeの左端っこにある、テトリスみたいなアイコンを押します。アイコンをクリックしたら、検索欄(Search Extensions in …)で追加したい拡張機能を検索します。 まずは「vscode-pandoc」と検索してみましょう。検索したら、vscode-pandoc をクリックします(私はバージョン0.0.8の方を使用しています)。あとはinstallボタンをクリックして少し待てば、インストール完了です。 拡張機能のインストールの仕方を説明しました。vscode-pandocの他にも、Pandoc Markdown Previewという拡張を必須として挙げています。先ほどと同様にインストールしましょう。 今インストールした2つの拡張以外にも便利な拡張機能がたくさんあるので、是非いろいろ試してみてください。 そして便利そうなやつは共有してください！ 4.4.3 簡易版TeX環境を作る TeX環境がすでに構築済みである方は手順4へ進んでください。 なぜTeX？と思われる方もいるかもしれません。 ここでTeXが必要な理由は、次のような理由からです。pandoc markdownをpdfに変換するときには、markdown → TeX → pdfという変換を行っています。したがって、TeXの環境が必要になるという訳です。 でも、TeXliveのインストールには労力がかかるのでやりません（私もTeXLiveはインストールしていません）。ではどうするかというとTinyTeXというものを使います。 TinyTeXとは、Rユーザー向けに作成された簡易TeX環境構築パッケージです。詳細はこちら（https://yihui.org/tinytex/）を参照ください。Rユーザー向けではありますが、vscodeでも十分に使えています（所感）。 ではTinyTeXをインストールしましょう。以下の2行のコマンドをRで実行するだけです。少々時間がかかると思います。コーヒーでも飲んで休憩して待ちましょう。 install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() 4.4.4 ipaexフォントをインストールする ここでは日本語pdfの作成に必要なフォントをインストールします。 もちろんipaexフォント以外でもpdfの作成はできますが、少々込み入った話になってくるので今回はipaexフォントを使用します。 こちらのlink(https://ipafont.ipa.go.jp/old/ )よりipaexフォントをダウンロードして、PCにインストールします。 フォントインストールの手順はOSに依存します。 4.4.5 YAML front matter さて、ここが少しだけ込み入った話になります。 pandoc markdown（pandocを使うmarkdown）では、yamlフロントマターというのをmarkdownの先頭に記述します。 3つのハイフン—で上下を囲ったやつです。 たとえばpandocでmarkdownからpdf出力するときはこんな感じのyamlフロントマターを書きます。 --- title: &quot;pandocでmarkdownから日本語pdf出力 in vscode&quot; subtitle: &quot;&quot; author: &quot;Akiyama Hiroki&quot; date: &quot;yyyy-mm-dd&quot; geometry: &quot;left=3cm,right=3cm,top=2cm,bottom=2cm&quot; output: pdf_document: latex_engine: xelatex header-includes: - \\usepackage{xltxtra} # 日本語pdf用 - \\usepackage{zxjatype} # 日本語pdf用 - \\usepackage[ipaex]{zxjafont} # フォント指定 --- 引数 意味 title タイトル subtitle サブタイトル author 著者 date 日付 geometry 文書の余白 output 出力形式 header-includes以下 TeXパッケージ指定 これらのyaml内容は。大体どの文書にも共通して記述するものになっています。 header-includes以下に関しては、今回の日本語pdf作成用になっています。この他にもyamlフロントマターへの記述で設定できることはとてもたくさんありますが、それらはまた今度紹介します。たぶん。 vscodeの便利な点として、pdfやhtml出力をする際のpandocの引数を、設定に保存しておくことができる点があります。 「ctrl + ,」で設定画面を開きます。pandocと検索すると、次のような画面が出てきます。 ここのPdf Opt Stringに、 --pdf-engine xelatex -V geometry:margin=1in などと記述しておくことで、レンダリングする際のpandocの引数を保存しておくことができます。 こうすると、yamlの該当部分は省略して書くことができます。 4.4.6 出力のコマンド 準備は整いました。「ctrl + k」を押した後に、「p」を押して、pdfを選択すればpdf出力が完了します！ 4.5 サンプルmd ここに04_sample.mdを置きました。中身に書いてあることは本記事とほぼ同じものです。これをvscodeで開き、ここまで説明してきた準備を終えていれば、「ctrl + k」を押した後に「p」を押して、pdf出力ができるはずです。 (数式もTeXで書けます) \\[ f(x)={\\displaystyle\\sum_{k=0}^{\\infty}}f^{(k)}(0)\\dfrac{x^k}{k!}\\\\=f(0)+f&#39;(0)x+\\dfrac{f”(0)}{2!}x^2+\\dfrac{f^{(3)}(0)}{3!}x^3\\cdots \\] enjoy! 4.6 追記 現状だと、プレビューまではできるけど、出力はうまくいかない Rstudioで一度knitすることで、tex変換に必要なパッケージをインストールしてくれる tlmgr install ipaexをする必要あり tinytex::tlmgr_install(“ipaex”) "],
["05_mystery.html", "Chapter: 5 slackの謎 5.1 投稿数激増！バトルドォーム！ 5.2 バトルドォーム！の差分 5.3 超！エキサイティン！！", " Chapter: 5 slackの謎 library(tidyverse) library(here) library(plotly) d &lt;- read_csv(here(&quot;data/slack0629.csv&quot;)) glimpse(d) Rows: 464 Columns: 21 $ 日付 &lt;date&gt; 2019-03-22, 2019-03-23, 2019-03-24, 2019-03-25, 2019-03-26, 2019-03-27, 2019-03-28,... $ メンバー数合計 &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 9, 12, 16, 19, 20, 21, 22, 22, 22, 24,... $ 通常メンバー &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 9, 12, 16, 19, 20, 21, 22, 22, 22, 24... $ ゲスト &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0... $ 日間アクティブメンバー数 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 8, 7, 10, 11, 9, 10, 4, 10, 14, 17, 4, 13, ... $ `メッセージを投稿したメンバー数の推移(日別)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 3, 2, 5, 3, 3, 1, 2, 4, 3, 2, 2, 3, 0, 3, 1, 2, ... $ 週間アクティブメンバー数 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 9, 12, 16, 19, 20, 21, 22, 21, 20, 20, 20, ... $ `メッセージを投稿したメンバー数の推移(週別)` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 7, 7, 9, 9, 10, 10, 9, 10, 10, 8, 7, 7, 6, 7, 6,... $ パブリックチャンネルのメッセージ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 5, 4, 7, 1, 2, 0, 12, 6, 2, 0, 1, 1, 0, 4, 1... $ プライベートチャンネルのメッセージ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ 共有チャンネルへの投稿メッセージ数 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ ダイレクトメッセージでの投稿メッセージ数 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 0, 5, 17, 9, 1, 0, 9, 5, 13, 4, 9, 0, 0, 0, 0... $ `メッセージの割合、パブリックチャンネル` &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.000... $ `メッセージの割合、プライベートチャンネル` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ `メッセージの割合、DM` &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0... $ `表示回数の割合、パブリックチャンネル` &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.00... $ `表示回数の割合、プライベートチャンネル` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... $ `表示回数の割合、DM` &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.... $ 名前 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... $ `パブリックチャンネル、1つのワークスペース` &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, ... $ 投稿されたメッセージ数 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 42, 65, 82, 105, 127, 146, 151, 169, 185,... long_d &lt;- d %&gt;% select(日付, メンバー数合計, 投稿されたメッセージ数) %&gt;% pivot_longer(-日付) p &lt;- long_d %&gt;% ggplot(aes(x = 日付, y = value)) + geom_line() + facet_wrap(facets = vars(name), ncol = 1, scales = &quot;free_y&quot;) + labs(title = &quot;バトルドォーム！ red：誕生、blue:お引越し&quot;, x = &quot;月&quot;, y = &quot;&quot;) + geom_vline(xintercept = as.Date(&quot;2020-02-12&quot;), color = &quot;red&quot;, size = 0.2) + geom_vline(xintercept = as.Date(&quot;2020-04-07&quot;), color = &quot;blue&quot;, size = 0.2) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) 5.1 投稿数激増！バトルドォーム！ ggplotly(p, dynamicTicks = T) p long_d &lt;- d %&gt;% select(日付, 投稿されたメッセージ数) long_d &lt;- long_d %&gt;% mutate(lag1 = 投稿されたメッセージ数 - lag(投稿されたメッセージ数)) p &lt;- long_d %&gt;% ggplot(aes(x = 日付, y = lag1)) + geom_line() + labs(title = &quot;前日の投稿メッセージ数からの増減 red：誕生、blue:お引越し&quot;, x = &quot;月&quot;, y = &quot;&quot;) + geom_vline(xintercept = as.Date(&quot;2020-02-12&quot;), color = &quot;red&quot;, size = 0.2) + geom_vline(xintercept = as.Date(&quot;2020-04-07&quot;), color = &quot;blue&quot;, size = 0.2) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) 5.2 バトルドォーム！の差分 ggplotly(p, dynamicTicks = T) p d2 &lt;- d %&gt;% select(日付, 日間アクティブメンバー数, パブリックチャンネルのメッセージ, プライベートチャンネルのメッセージ, ダイレクトメッセージでの投稿メッセージ数) p2 &lt;- d2 %&gt;% pivot_longer(-日付) %&gt;% ggplot(aes(x = 日付, y = value)) + geom_line() + facet_wrap(facets = vars(name), ncol = 1, scales = &quot;free_y&quot;) + labs(title = &quot;超！エキサイティン！！ red：誕生、blue:お引越し&quot;, x = &quot;月&quot;, y = &quot;&quot;) + geom_vline(xintercept = as.Date(&quot;2020-02-12&quot;), color = &quot;red&quot;, size = 0.2) + geom_vline(xintercept = as.Date(&quot;2020-04-07&quot;), color = &quot;blue&quot;, size = 0.2) + scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) 5.3 超！エキサイティン！！ plotly::ggplotly(p2, dynamicTicks = TRUE) p2 "],
["06_NBA_cluster.html", "Chapter: 6 NBAのスタッツデータでクラスタリング 6.1 前処理 6.2 可視化 6.3 kmeansでクラスタリング 6.4 雑感", " Chapter: 6 NBAのスタッツデータでクラスタリング ここ （https://www.kaggle.com/drgilermo/nba-players-stats） に公開されているNBA選手のスタッツや身長体重などのデータを用いて、クラスタリングをおこなう。 kmeansを使用し、クラスタ数は2,3,5の3パターンを試した。 バスケのポジションごとにクラスタとなればいいなと期待していた。 しかし結果としては、スタメンやスター選手、控えの選手、あまり出場機会がない選手というようなクラスタに別れた。 以下にコードと結果を示す。 6.1 前処理 6.1.1 ライブラリとデータ読み込み library(tidyverse) library(dplyr) library(ggplot2) library(purrr) library(tibble) library(tidyr) library(tidymodels) library(factoextra) library(NbClust) library(patchwork) library(naniar) # vis_miss library(ggrepel) library(here) read_csvの自動識別だと微妙なので、読み込むカラム型を事前に決めておく。 set_coltypes &lt;- cols( .default = col_double(), Year = col_double(), Player = col_character(), Pos = col_character(), Age = col_double(), Tm = col_character(), G = col_double(), GS = col_double(), MP = col_double(), PER = col_double(), `TS%` = col_double(), `3PAr` = col_double(), FTr = col_double(), `ORB%` = col_double(), `DRB%` = col_double(), `TRB%` = col_double(), `AST%` = col_double(), `STL%` = col_double(), `BLK%` = col_double(), `TOV%` = col_double(), `USG%` = col_double(), blanl = col_skip(), OWS = col_double(), DWS = col_double(), WS = col_double(), `WS/48` = col_double(), blank2 = col_skip(), OBPM = col_double(), DBPM = col_double(), BPM = col_double(), VORP = col_double(), FG = col_double(), FGA = col_double(), `FG%` = col_double(), `3P` = col_double(), `3PA` = col_double(), `3P%` = col_double(), `2P` = col_double(), `2PA` = col_double(), `2P%` = col_double(), `eFG%` = col_double(), FT = col_double(), FTA = col_double(), `FT%` = col_double(), ORB = col_double(), DRB = col_double(), TRB = col_double(), AST = col_double(), STL = col_double(), BLK = col_double(), TOV = col_double(), PF = col_double(), PTS = col_double() ) Seasons_Stats.csvを読み込む。Players.csvを読み込む。Playersから身長と体重のカラムを、Seasons_Statsにジョインさせる。ジョインしたものをdataとする。 players &lt;- read_csv(here(&quot;data/Players.csv&quot;)) seasons_stats &lt;- read_csv(here(&quot;data/Seasons_Stats.csv&quot;), col_types = set_coltypes) data &lt;- players %&gt;% select(Player, height, weight) %&gt;% right_join(seasons_stats, by = &quot;Player&quot;) 6.1.2 データの整理 データを2000年以降に絞る 古いデータはスタッツが取れていなくて欠損が多いため 選手の名前で、最新のデータから順にユニークをとる X1 はインデックスなので消去する 最新の選手データに絞ったので、Yearはもう不要だから消去 data_2000_uniquename &lt;- data %&gt;% filter(Year &gt;= 2000) %&gt;% arrange(desc(Year)) %&gt;% distinct(Player, .keep_all = TRUE) %&gt;% select(-X1, -Year) 6.1.3 各ポジションの選手数 data_2000_uniquename %&gt;% group_by(Pos) %&gt;% count # A tibble: 14 x 2 # Groups: Pos [14] Pos n &lt;chr&gt; &lt;int&gt; 1 C 362 2 C-PF 4 3 C-SF 1 4 PF 318 5 PF-C 3 6 PF-SF 1 7 PG 325 8 PG-SG 4 9 SF 333 10 SF-PF 5 11 SF-SG 3 12 SG 322 13 SG-PG 5 14 SG-SF 4 6.1.4 ５つのポジションにする C-PFや、PG-SGなどの2ポジション登録されているものは数が少ないので消去して、5つのポジション(PG, SG, SF, PF, C)のみにする。 data_2000_uniquename_5pos &lt;- data_2000_uniquename %&gt;% filter(Pos %in% c(&quot;PG&quot;, &quot;SG&quot;, &quot;SF&quot;, &quot;PF&quot;, &quot;C&quot;)) %&gt;% mutate(Pos = fct_relevel(Pos ,&quot;PG&quot;, &quot;SG&quot;, &quot;SF&quot;, &quot;PF&quot;, &quot;C&quot;)) 6.1.5 欠損の可視化 data_2000_uniquename_5pos %&gt;% vis_miss() 6.1.6 欠損の除去 3P%とFT%の欠損は、3PとFTのアテンプトがないことによるものである（たぶん）。 3Pと3PAの値は入っているため、3P%は情報量として特に意味がないので使用しないことにする。 同様にしてFT%も使用しないこととする。 その他に欠損が存在しているレコードは数が少ないので、それらのレコードは除いて分析をおこなうことにする。 data_2000_uniquename_5pos_clean &lt;- data_2000_uniquename_5pos %&gt;% select(-`3P%`, -`FT%`) %&gt;% drop_na() data_2000_uniquename_5pos_clean %&gt;% vis_miss() 欠損値がなくなった綺麗なデータができあがった。 6.1.7 チームの略称を整理する 現在のNBAは東西合わせて30チームある。今扱っているデータには、チームの略称が変わっているものなどが存在するので、それを統一する。 CHH, CHOは、現在のCHAなので、CHAに統一する。 NJNはニュージャージーネッツ、現在のブルックリンネッツなので、BRKに統一する。 NOH, NOKは、現在のNOPだから統一する。 TOTは、シーズン途中で移籍した選手に関して、移籍前と後の成績を足し合わせたもの。だから、今回はTOTは外す。 VANはバンクーバーグリズリーズ、現在のメンフィスグリズーズだから、MEMに統一する。 SEAはOKCに統一する。 data_2000_uniquename_5pos_clean &lt;- data_2000_uniquename_5pos_clean %&gt;% mutate(Tm_30 = case_when( Tm %in% c(&quot;CHH&quot;, &quot;CHO&quot;) ~ &quot;CHA&quot;, Tm == &quot;NJN&quot; ~ &quot;BRK&quot;, Tm %in% c(&quot;NOH&quot;, &quot;NOK&quot;) ~ &quot;NOP&quot;, Tm == &quot;VAN&quot; ~ &quot;MEM&quot;, Tm == &quot;SEA&quot; ~ &quot;OKC&quot;, TRUE ~ Tm) # case_whenを使うときはTRUE のケースを忘れないように注意する ) %&gt;% filter(Tm != &quot;TOT&quot;) 6.2 可視化 6.2.1 クラスタリングに使用するデータ 6.2.2 PCAしてみる rec_preped &lt;- data_2000_uniquename_5pos_clean %&gt;% recipe() %&gt;% step_center(all_numeric()) %&gt;% step_scale(all_numeric()) %&gt;% step_pca(all_numeric(), threshold = .80) %&gt;% prep() t &lt;- rec_preped$steps[[3]]$res %&gt;% summary() t$importance %&gt;% broom::tidy() %&gt;% pivot_longer(-.rownames) %&gt;% filter(.rownames == &quot;Cumulative Proportion&quot;) %&gt;% mutate(name = as_factor(name)) %&gt;% ggplot(aes(x = name, y = value)) + geom_point() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme(text = element_text(family = &quot;Japan1GothicBBB&quot;)) + labs(x = &quot;&quot;, y = &quot;累積寄与率&quot;, title = &quot;主成分分析の累積寄与率&quot;) + ylim(0,1) data_pca80 &lt;- rec_preped %&gt;% juice() 6.2.3 PCAの２軸でポジション別プロット p_pca &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = Pos)) + geom_point() + labs(title = &quot;PCAの2軸で でポジション別&quot;) p_pca 6.2.4 チーム別ポジション別でPCA２軸 p_pca_facet_team &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = Pos)) + geom_point() + facet_wrap(vars(Tm_30)) p_pca_facet_team 一部の選手のみラベルを表示させるために、ラベルのカラムを作成する。 data_pca80 &lt;- data_pca80 %&gt;% mutate(label = if_else(condition = (10 &lt;= PC1| 5 &lt;= PC2), true = as.character(Player), false = &quot;&quot; )) p_pca_facet_team_label &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = Pos, label = label)) + geom_point() + geom_text_repel() + facet_wrap(vars(Tm_30)) p_pca_facet_team_label 6.3 kmeansでクラスタリング 6.3.1 エルボー法とシルエット法でクラスタ数チェック # Elbow method p_elbow &lt;- data_2000_uniquename_5pos_clean %&gt;% select(where(is.numeric)) %&gt;% fviz_nbclust(kmeans, method = &quot;wss&quot;) + geom_vline(xintercept = 3, linetype = 2) + # add line for better visualisation labs(subtitle = &quot;Elbow method&quot;) # add subtitle p_silhouette &lt;- data_2000_uniquename_5pos_clean %&gt;% select(where(is.numeric)) %&gt;% fviz_nbclust(kmeans, method = &quot;silhouette&quot;) + labs(subtitle = &quot;Silhouette method&quot;) p_elbow | p_silhouette エルボーでは3、シルエットでは2がよさそう。 6.3.2 kmeans２と３と５ my_kmeans &lt;- function(data, centers, nstart = 50){ model &lt;- data %&gt;% select(where(is.numeric)) %&gt;% kmeans(centers = centers, nstart = nstart) cat(&quot;クラスタ数&quot;, centers ,&quot;, クラスタ間分散/全体分散 * 100 = &quot;, 100 * model$betweenss / model$totss, &quot;\\n&quot;) return(as.character(model$cluster)) } set.seed(7777) data_2000_uniquename_5pos_clean$kmeans2 &lt;- my_kmeans(data_2000_uniquename_5pos_clean, centers = 2, nstart = 50) クラスタ数 2 , クラスタ間分散/全体分散 * 100 = 69.22037 set.seed(7777) data_2000_uniquename_5pos_clean$kmeans3 &lt;- my_kmeans(data_2000_uniquename_5pos_clean, centers = 3, nstart = 50) クラスタ数 3 , クラスタ間分散/全体分散 * 100 = 83.51925 set.seed(7777) data_2000_uniquename_5pos_clean$kmeans5 &lt;- my_kmeans(data_2000_uniquename_5pos_clean, centers = 5, nstart = 50) クラスタ数 5 , クラスタ間分散/全体分散 * 100 = 91.14289 6.3.3 結果をPCAの2軸で可視化してみる。 rec_preped &lt;- data_2000_uniquename_5pos_clean %&gt;% recipe() %&gt;% step_center(all_numeric()) %&gt;% step_scale(all_numeric()) %&gt;% step_pca(all_numeric(), threshold = .80) %&gt;% prep() data_pca80 &lt;- rec_preped %&gt;% juice() cluster_2 &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = kmeans2)) + geom_point() + labs(title = &quot;PCAの2軸で 2クラスタ&quot;) + theme(legend.position = &quot;bottom&quot;) cluster_3 &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = kmeans3)) + geom_point() + labs(title = &quot;PCAの2軸で 3クラスタ&quot;) + theme(legend.position = &quot;bottom&quot;) cluster_5 &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = kmeans5)) + geom_point() + labs(title = &quot;PCAの2軸で 5クラスタ&quot;) + theme(legend.position = &quot;bottom&quot;) (p_pca | cluster_2) / (cluster_3 | cluster_5) お世辞にもポジションでクラスタに分かれたようには見えへん！！！！ 近年のNBAでは、どのポジションでもドリブル・シュート・アシストなどが高いレベルでできることが求められている。 改めて考えると、身長体重やスタッツのデータがポジションごとでクラスタになるのは、確かにありえないか、とも思う。 とりあえず固まった、３クラスタで見ていく。 6.3.4 チーム別kmeansプロット インタラクティブなプロットになってます。 p_pca_facet_team_kmeans3 &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = kmeans3, label = Player)) + geom_point() + facet_wrap(vars(Tm_30)) # p_pca_facet_team_kmeans3 plotly::ggplotly(p_pca_facet_team_kmeans3, dynamicTicks = T) 6.3.5 選手名つき インタラクティブプロットを見る感じ、どうやら緑のクラスタは、スタメンやスター級の選手が固まっているらしい。 一部の選手のみラベルを表示させるために、ラベルのカラムを作成する。PC1が10以上の選手のみラベルをつける。 data_pca80 &lt;- data_pca80 %&gt;% mutate(label = if_else(condition = (10 &lt;= PC1), true = as.character(Player), false = &quot;&quot; )) p_pca_facet_team_label_kmeans3 &lt;- data_pca80 %&gt;% ggplot(aes(PC1, PC2, color = kmeans3, label = label)) + geom_point() + geom_text_repel() + facet_wrap(vars(Tm_30)) p_pca_facet_team_label_kmeans3 やはりスター選手やスタメンの選手がほぼすべてである。 6.3.6 スタメンかどうかでわける 半分以上の試合でスタメンの選手のみで、クラスタの集計をしてみる。 data_pca80 %&gt;% left_join(data_2000_uniquename_5pos_clean %&gt;% select(Player, GS), by = &quot;Player&quot;) %&gt;% filter(GS &gt;= 41) %&gt;% group_by(kmeans3) %&gt;% count() # A tibble: 2 x 2 # Groups: kmeans3 [2] kmeans3 n &lt;fct&gt; &lt;int&gt; 1 1 39 2 2 120 逆に、半分の試合でスタメンでないクラスタを集計するとこうなる。 data_pca80 %&gt;% left_join(data_2000_uniquename_5pos_clean %&gt;% select(Player, GS), by = &quot;Player&quot;) %&gt;% filter(GS &lt;= 41) %&gt;% group_by(kmeans3) %&gt;% count() # A tibble: 3 x 2 # Groups: kmeans3 [3] kmeans3 n &lt;fct&gt; &lt;int&gt; 1 1 299 2 2 38 3 3 926 6.4 雑感 ポジションクラスタという期待していた結果にはならなかったが、これはこれで面白い結果になったと思う。 クラスタリングにかけるデータを取捨選択するとかなんとかすれば（たとえば身長・体重と何かだけとか）、ポジションクラスタもできるかもしれない。 他にも、年代別とかでもっと分析ができそうだなと感じた。時間があればやる！！！！ "]
]
