[
["index.html", "日々の雑学 はじめに 0.1 環境", " 日々の雑学 Akiyama Hiroki 最終更新日: 2020-05-20 はじめに 作成中です hogehoge fugafuga 0.1 環境 sessionInfo() ## R version 3.6.3 (2020-02-29) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 18363) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Japanese_Japan.932 LC_CTYPE=Japanese_Japan.932 LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C ## [5] LC_TIME=Japanese_Japan.932 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] stringi_1.4.6 leaflet_2.0.3 ggmap_3.0.0 DT_0.13 lubridate_1.7.8 jsonlite_1.6.1 ## [7] bookdown_0.18 patchwork_1.0.0 imager_0.42.3 magrittr_1.5 tictoc_1.0 microbenchmark_1.4-7 ## [13] xgboost_1.0.0.2 furrr_0.1.0 future_1.16.0 yardstick_0.0.6 workflows_0.1.1 tune_0.1.0 ## [19] rsample_0.0.6 recipes_0.1.10 parsnip_0.1.0 infer_0.5.1 dials_0.0.6 scales_1.1.0 ## [25] broom_0.5.5 tidymodels_0.1.0 forcats_0.5.0 stringr_1.4.0 dplyr_0.8.5 purrr_0.3.3 ## [31] readr_1.3.1 tidyr_1.0.2 tibble_3.0.0 ggplot2_3.3.0 tidyverse_1.3.0 here_0.1 ## ## loaded via a namespace (and not attached): ## [1] pacman_0.5.1 utf8_1.1.4 tidyselect_1.0.0 lme4_1.1-21 htmlwidgets_1.5.1 grid_3.6.3 ## [7] ranger_0.12.1 pROC_1.16.2 munsell_0.5.0 codetools_0.2-16 miniUI_0.1.1.1 withr_2.1.2 ## [13] colorspace_1.4-1 knitr_1.28 rstudioapi_0.11 stats4_3.6.3 bayesplot_1.7.1 listenv_0.8.0 ## [19] labeling_0.3 rstan_2.19.3 RgoogleMaps_1.4.5.3 DiceDesign_1.8-1 farver_2.0.3 rprojroot_1.3-2 ## [25] vctrs_0.2.99.9011 generics_0.0.2 TH.data_1.0-10 ipred_0.9-9 xfun_0.12 R6_2.4.1 ## [31] markdown_1.1 rstanarm_2.19.3 bitops_1.0-6 lhs_1.0.1 assertthat_0.2.1 promises_1.1.0 ## [37] multcomp_1.4-13 nnet_7.3-13 gtable_0.3.0 globals_0.12.5 bmp_0.3 processx_3.4.2 ## [43] sandwich_2.5-1 timeDate_3043.102 rlang_0.4.6 splines_3.6.3 ModelMetrics_1.2.2.2 inline_0.3.15 ## [49] yaml_2.2.1 reshape2_1.4.3 modelr_0.1.6 tidytext_0.2.3 threejs_0.3.3 crosstalk_1.1.0.1 ## [55] backports_1.1.6 httpuv_1.5.2 rsconnect_0.8.16 tokenizers_0.2.1 caret_6.0-86 tools_3.6.3 ## [61] lava_1.6.7 ellipsis_0.3.0 ggridges_0.5.2 Rcpp_1.0.4.6 plyr_1.8.6 base64enc_0.1-3 ## [67] ps_1.3.2 prettyunits_1.1.1 rpart_4.1-15 zoo_1.8-7 haven_2.2.0 fs_1.4.1 ## [73] data.table_1.12.8 readbitmap_0.1.5 colourpicker_1.0 reprex_0.3.0 GPfit_1.0-8 mvtnorm_1.1-0 ## [79] SnowballC_0.7.0 packrat_0.5.0 matrixStats_0.56.0 tidyposterior_0.0.2 hms_0.5.3 shinyjs_1.1 ## [85] mime_0.9 evaluate_0.14 xtable_1.8-4 tidypredict_0.4.5 shinystan_2.5.0 jpeg_0.1-8.1 ## [91] readxl_1.3.1 gridExtra_2.3 rstantools_2.0.0 compiler_3.6.3 crayon_1.3.4 minqa_1.2.4 ## [97] StanHeaders_2.21.0-1 htmltools_0.4.0 later_1.0.0 tiff_0.1-5 DBI_1.1.0 dbplyr_1.4.2 ## [103] MASS_7.3-51.5 boot_1.3-24 Matrix_1.2-18 cli_2.0.2 parallel_3.6.3 gower_0.2.1 ## [109] igraph_1.2.5 pkgconfig_2.0.3 sp_1.4-1 xml2_1.3.1 foreach_1.5.0 dygraphs_1.1.1.6 ## [115] hardhat_0.1.2 prodlim_2019.11.13 rvest_0.3.5 janeaustenr_0.1.5 callr_3.4.3 digest_0.6.25 ## [121] rmarkdown_2.1 cellranger_1.1.0 shiny_1.4.0.2 gtools_3.8.2 rjson_0.2.20 nloptr_1.2.2.1 ## [127] lifecycle_0.2.0 nlme_3.1-145 fansi_0.4.1 pillar_1.4.3 lattice_0.20-41 loo_2.2.0 ## [133] fastmap_1.0.1 httr_1.4.1 pkgbuild_1.0.6 survival_3.1-11 glue_1.4.0 xts_0.12-0 ## [139] png_0.1-7 shinythemes_1.1.2 iterators_1.0.12 class_7.3-16 e1071_1.7-3 "],
["01_android_analysis.html", "Chapter: 1 android分析 1.1 ライブラリの準備 1.2 activityをダウンロード 1.3 ここから解析", " Chapter: 1 android分析 1.1 ライブラリの準備 pacman::p_loadを使うと、ライブラリをまとめて読み込んでくれます。また、インストールされていないライブラリがある場合は、インストールかつ読み込みを行ってくれます。 pacmanがインストールされていない場合は、コメントアウトしてインストールしてください。 # install.packages(pacman) pacman::p_load(tidyverse, jsonlite, patchwork, here, lubridate, update = FALSE) 1.2 activityをダウンロード あとで書く google takeout で検索 1.3 ここから解析 1.3.1 activityの読み込み android &lt;- jsonlite::fromJSON(here(&quot;data/android_activity.json&quot;)) 1.3.2 読み込んだactivityデータの概要確認 glimpse(android) ## Rows: 63,120 ## Columns: 5 ## $ header [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;びよーんったー Pro&quot;, &quot;Nova Launcher ホーム&quot;, &quot;Gmail&quot;, &quot;Slack&quot;, &quot;Nova Launcher ホーム&quot;, &quot;com.android.systemui&quot;, &quot;LINE（ライン） - 無料通話・メールアプリ&quot;, &quot;び... ## $ title [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;使用: びよーんったー Pro&quot;, &quot;使用: Nova Launcher ホーム&quot;, &quot;使用: Gmail&quot;, &quot;使用: Slack&quot;, &quot;使用: Nova Launcher ホーム&quot;, &quot;使用: com.android.systemui&quot;, &quot;使用: ... ## $ titleUrl [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;https://play.google.com/store/apps/details?id=com.ABS104a.biyontterpro&quot;, &quot;https://play.google.com/store/apps/details?id=com.tes... ## $ time [3m[38;5;246m&lt;chr&gt;[39m[23m &quot;2020-04-16T21:29:57.048Z&quot;, &quot;2020-04-16T21:29:54.832Z&quot;, &quot;2020-04-16T21:29:28.111Z&quot;, &quot;2020-04-16T21:27:42.460Z&quot;, &quot;2020-04-16T14:2... ## $ products [3m[38;5;246m&lt;list&gt;[39m[23m [&quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Android&quot;, &quot;Andr... 1.3.3 timeデータを変換 android &lt;- android %&gt;% mutate(time = parse_datetime(time, locale = locale(tz = &quot;Japan&quot;)) ) %&gt;% mutate(date = lubridate::date(time), year = lubridate::year(time)) 1.3.4 年月ごとのデータ数の集計 2018年8月以前のデータが少ない。 activityデータの収集がうまくいっていなかった？ android %&gt;% group_by(year, month(date)) %&gt;% count() ## # A tibble: 37 x 3 ## # Groups: year, month(date) [37] ## year `month(date)` n ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2016 12 2 ## 2 2017 1 1 ## 3 2017 2 56 ## 4 2017 3 26 ## 5 2017 5 6 ## 6 2017 6 64 ## 7 2017 7 12 ## 8 2017 8 29 ## 9 2017 9 32 ## 10 2017 11 4 ## # ... with 27 more rows android %&gt;% count(date) %&gt;% ggplot() + geom_line(aes(date,n)) + scale_x_date(breaks = &quot;month&quot;, guide = guide_axis(n.dodge = 3)) 1.3.5 データの準備 2019年と2020年のデータのみを使うことにする。 android_latest &lt;- android %&gt;% filter(year %in% c(2019, 2020)) アプリの名前が長いから20文字までにする。 android_latest &lt;- android_latest %&gt;% mutate(header = if_else(str_length(header) &gt;= 20, substr(header, 1, 20), header)) android &lt;- android %&gt;% mutate(header = if_else(str_length(header) &gt;= 20, substr(header, 1, 20), header)) 1.3.6 アプリの使用回数（2019-2020） android_latest %&gt;% count(header, sort = TRUE) %&gt;% head(5) %&gt;% mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + theme_minimal() + labs(title = &quot;Most used Apps - Overall&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) 1.3.7 アプリの使用回数（すべての年） android %&gt;% count(header, sort = TRUE) %&gt;% head(5) %&gt;% mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + theme_minimal() + labs(title = &quot;Most used Apps - Overall&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) 1.3.8 比較（2019 vs 2020） android_latest %&gt;% filter(year %in% &#39;2019&#39;) %&gt;% group_by(year, header) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% #View() mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + # facet_wrap(~year, scales = &quot;free&quot;) + theme_minimal() + labs(title = &quot;Most used Apps - 2019&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) -&gt; p2019 android_latest %&gt;% filter(year %in% &#39;2020&#39;) %&gt;% group_by(year, header) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% #View() mutate(header = fct_reorder(header, n)) %&gt;% ggplot() + geom_col(aes(y = header, x = n)) + # facet_wrap(~year, scales = &quot;free&quot;) + theme_minimal() + labs(title = &quot;Most used Apps - 2020&quot;, subtitle = &quot;Android Smartphone usage&quot;, caption = &quot;Data:Google Takeout&quot;) -&gt; p2020 p2019 / p2020 "],
["02_standard_input.html", "Chapter: 2 標準入力 2.1 readLines 2.2 スクリプトで計算処理 2.3 テキストファイルを読ませる", " Chapter: 2 標準入力 標準入力、つまりはPythonで言うところのinput()をRでやろうとしたら、かなり苦労したのでtipsとしてまとめておくことにした。 2.1 readLines ずばりRで標準入力をするにはreadLinesを使う。ただし、 input_lines &lt;- readLines(&quot;stdin&quot;) このように\"stdin\"という引数を使用する。おそらくstandard input の略か何かだろう。 注意すべきは、このコードをRのコンソールで実行してしまうとRがうんともすんとも言わなくなってしまうこと。 詳しい理由はわからないが、コマンドプロンプトからの標準入力を受けるように指示しているので、コンソールで実行してしまうとダメ、ということなのだろうか（誰か教えて欲しい）。 コンソール上で実験的にコードを試したい場合は、readline()を使えばコンソールで入力待ち状態となるので、こちらを使用する。 たとえばstdin.Rに下記のように記述しておき、 #! /usr/bin/env Rscript input_lines &lt;- readLines(&quot;stdin&quot;) cat(input_lines[1]) # catは標準出力 コマンドプロンプトから下記のようにしてstdin.Rを実行してみる Rscript stdin.R すると入力待ち状態になるので、何かしら記述する。 Hello world! そして、ctrl + cあるいはctrl + zの後にEnterで入力を終了すると（他の方法ありますか？） Hello world! とプロンプトに標準出力ができる。 2.2 スクリプトで計算処理 stdin.Rに以下のように記述しておけば、標準入力で受け取った値を、計算処理をしてから返すこともできる。 #! /usr/bin/env Rscript # ライブラリもつかえる library(tidyverse) input_lines &lt;- readLines(&quot;stdin&quot;) x = as.integer(input_lines[1]) # 1つめ（1行目の入力） y = as.integer(input_lines[2]) # 2つめ cat(x + y) 2.3 テキストファイルを読ませる read_text.txtを別に以下のように準備しておき、 （read_text.txtの最終行には改行を入れないと、あとでwarningが出るので注意する。） Hello world! stdin.Rをこうしておく #! /usr/bin/env Rscript input_lines &lt;- readLines(&quot;stdin&quot;) x = input_lines[1] y = input_lines[2] cat(x, y) そしてコマンドプロンプトで次のようにすれば、read_text.txtから標準入力を受け取ることができる。 Rscript stdin.R &lt; read_text.txt プロンプトの出力はこうなる Hello world! これでatcoderにも参戦できる！ （atcoderでRは使用不可、、、） "],
["03_ido_keido.html", "Chapter: 3 緯度経度からちょっとインタラクティブな地図作成 3.1 ライブラリ読み込み 3.2 データ準備 3.3 ポップアップの文字作成 3.4 マーカーリスト 3.5 地図にプロットする 3.6 データ一覧 3.7 マーカーリスト 3.8 地図にプロットするその２", " Chapter: 3 緯度経度からちょっとインタラクティブな地図作成 参考にした記事 というかほぼこれ https://rpubs.com/kazutan/jssp2015_leaflet 3.1 ライブラリ読み込み library(tidyverse) library(here) library(DT) # 表作成用 library(ggmap) # 住所・緯度経度対応用 library(leaflet) # プロット用 library(stringi) # 全角から半角変換 3.2 データ準備 緯度経度取得後の想定データ # 東京ドーム 日本、〒112-0004 東京都文京区後楽１丁目３−６１ 35.7056396 139.7518913 # 福島聖天通商店街 日本、〒553-0003 大阪府大阪市福島区福島７丁目７−１２ 34.6976052 135.4846712 # 銀座通り商店街 日本、〒489-0043 愛知県瀬戸市朝日町 35.2266746 137.100508 df &lt;- tribble( ~id, ~lat, ~lon, ~address, ~group, ~name, 1, 35.7056396, 139.7518913,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;スポーツ&quot;, &quot;東京ドーム&quot;, 2, 34.6976052, 135.4846712,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;商店街A&quot; ,&quot;福島聖天通商店街&quot;, 3, 35.2266746, 137.100508,&quot;〒112-0004 東京都文京区後楽１丁目３−６１&quot;, &quot;商店街B&quot;, &quot;銀座通り商店街&quot; ) # https://www.pediatricsurgery.site/entry/2017/10/12/105242 df &lt;- df %&gt;% mutate(address = stri_trans_nfkc(address)) # 住所の全角を半角に変換 df ## # A tibble: 3 x 6 ## id lat lon address group name ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 35.7 140. 〒112-0004 東京都文京区後楽1丁目3-61 スポーツ 東京ドーム ## 2 2 34.7 135. 〒112-0004 東京都文京区後楽1丁目3-61 商店街A 福島聖天通商店街 ## 3 3 35.2 137. 〒112-0004 東京都文京区後楽1丁目3-61 商店街B 銀座通り商店街 3.3 ポップアップの文字作成 df &lt;- df %&gt;% mutate(popup = paste(name, group, address, sep=&quot;&lt;br/&gt;&quot;)) df ## # A tibble: 3 x 7 ## id lat lon address group name popup ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 35.7 140. 〒112-0004 東京都文京区後楽1丁目3-61 スポーツ 東京ドーム 東京ドーム&lt;br/&gt;スポーツ&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61 ## 2 2 34.7 135. 〒112-0004 東京都文京区後楽1丁目3-61 商店街A 福島聖天通商店街 福島聖天通商店街&lt;br/&gt;商店街A&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61~ ## 3 3 35.2 137. 〒112-0004 東京都文京区後楽1丁目3-61 商店街B 銀座通り商店街 銀座通り商店街&lt;br/&gt;商店街B&lt;br/&gt;〒112-0004 東京都文京区後楽1丁目3-61 3.4 マーカーリスト icon_df &lt;- tibble(group = df$group, icon = paste0(here(&quot;picture/icon/&quot;), &quot;/&quot;,dir(here(&quot;picture/icon/&quot;))[1:3])) icon_df ## # A tibble: 3 x 2 ## group icon ## &lt;chr&gt; &lt;chr&gt; ## 1 スポーツ C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-black.png ## 2 商店街A C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-blue.png ## 3 商店街B C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-gold.png 3.5 地図にプロットする # iconの高さと幅 w &lt;- 20 h &lt;- 30 geo &lt;- df %&gt;% leaflet() %&gt;% addTiles() for (gru in df$group){ icon_list &lt;- icons(iconUrl = icon_df %&gt;% filter(group == gru) %&gt;% pull(icon), iconWidth = w, iconHeight = h, iconAnchorX = w/2, iconAnchorY = h) geo &lt;- geo %&gt;% addMarkers(lng = ~lon, lat = ~lat, popup = ~popup, group = gru, icon = icon_list, data = dplyr::filter(.data = df, group == gru)) %&gt;% addLayersControl(overlayGroups = df$group, options = layersControlOptions(collapsed = FALSE)) } geo 3.6 データ一覧 # 一覧表示 DT::datatable(dplyr::select(df,name:group),options = list(searchHighlight = TRUE), filter = &#39;top&#39;) 3.7 マーカーリスト icon_df &lt;- tibble(group = unique(df$group), icon = paste0(here(&quot;picture/icon/&quot;), &quot;/&quot;,dir(here(&quot;picture/icon/&quot;))[1:3])) icon_df ## # A tibble: 3 x 2 ## group icon ## &lt;chr&gt; &lt;chr&gt; ## 1 スポーツ C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-black.png ## 2 商店街A C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-blue.png ## 3 商店街B C:/Users/AkiyamaHiroki/Desktop/my_trivial/picture/icon/marker-icon-2x-gold.png 3.8 地図にプロットするその２ # iconの高さと幅 # w &lt;- 20 # h &lt;- 30 # geo &lt;- df %&gt;% leaflet() %&gt;% addTiles() # # for (gru in unique(df$group)){ # # icon_list &lt;- icons(iconUrl = icon_df %&gt;% filter(group == gru) %&gt;% pull(icon), # iconWidth = w, iconHeight = h, # iconAnchorX = w/2, iconAnchorY = h) # # geo &lt;- geo %&gt;% # addMarkers(lng = ~lon, lat = ~lat, popup = ~popup, group = gru, # icon = icon_list, # data = dplyr::filter(.data = df, group == gru)) %&gt;% # addLayersControl(overlayGroups = unique(df$group), # options = layersControlOptions(collapsed = FALSE)) # } # geo "],
["04_img_classfication.html", "Chapter: 4 画像処理と多クラス分類 4.1 概要説明 4.2 結果 4.3 ライブラリ読み込み 4.4 データ読み込み 4.5 「あいうえお」を見てみる 4.6 前処理 4.7 モデリング 4.8 計測", " Chapter: 4 画像処理と多クラス分類 4.1 概要説明 あとで書く 4.2 結果 あとで書く 4.3 ライブラリ読み込み library(here) # file path library(tidyverse) # handling library(tidymodels) # modeling library(furrr) # parallel library(xgboost) # modeling xgboost library(microbenchmark) # time check library(tictoc) # time check library(imager) # image processing library(patchwork) # plot 4.4 データ読み込み 22秒くらいかかる。 tic() path_vec &lt;- here(paste0(&quot;data/hiragana/&quot;, 1:6069, &quot;.png&quot;)) data &lt;- path_vec %&gt;% map(load.image) %&gt;% tibble(images = .) toc() ## 15.13 sec elapsed 4.5 「あいうえお」を見てみる data$images[1:5] %&gt;% map(plot) ## [[1]] ## Image. Width: 72 pix Height: 76 pix Depth: 1 Colour channels: 1 ## ## [[2]] ## Image. Width: 72 pix Height: 76 pix Depth: 1 Colour channels: 1 ## ## [[3]] ## Image. Width: 72 pix Height: 76 pix Depth: 1 Colour channels: 1 ## ## [[4]] ## Image. Width: 72 pix Height: 76 pix Depth: 1 Colour channels: 1 ## ## [[5]] ## Image. Width: 72 pix Height: 76 pix Depth: 1 Colour channels: 1 4.6 前処理 余計な部分を削る。 横は20～50まで、縦は20～60まで。 preprocessing &lt;- function(img){ mat &lt;- img %&gt;% as.matrix() mat_reshape_img &lt;- mat[20:50, 20:60] %&gt;% as.cimg() mat_reshape_img } data &lt;- data %&gt;% mutate(processed = map(images, preprocessing)) data$processed[[1]] %&gt;% plot 画像を一次元のベクトルに変換する。 正解のラベルをつける。 わ行の「い」と「う」と「え」、は「い2」「う2」「え2」 旧文字の「い」と「え」は「い3」「え3」とした。 s &lt;- str_c(&quot;あいうえおかきくけこさしすせそたちつてとなにぬねのはひふへほまみむめも&quot;) s &lt;- str_split(s, pattern = &quot;&quot;)[[1]] s &lt;- c(s ,&quot;や&quot;,&quot;い2&quot;,&quot;ゆ&quot;,&quot;え2&quot;,&quot;よ&quot;,&quot;ら&quot;,&quot;り&quot;,&quot;る&quot;,&quot;れ&quot;,&quot;ろ&quot;,&quot;わ&quot;,&quot;い3&quot;,&quot;う2&quot;,&quot;え3&quot;,&quot;を&quot;,&quot;ん&quot;) data &lt;- data %&gt;% mutate(vec_img = processed %&gt;% map(as.vector)) %&gt;% mutate(label = rep(s, 119)) # それぞれ119文字ずつある。 data %&gt;% head() ## # A tibble: 6 x 4 ## images processed vec_img label ## &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; あ ## 2 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; い ## 3 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; う ## 4 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; え ## 5 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; お ## 6 &lt;cimg&gt; &lt;cimg&gt; &lt;dbl [1,271]&gt; か make_data &lt;- function(data, start, end){ d &lt;- data %&gt;% filter(label %in% s[start:end]) %&gt;% select(-images, -processed) tic() cols &lt;- paste0(&quot;pixel&quot;, 1:1271) res &lt;- d$vec_img[[1]] names(res) &lt;- cols for (i in 2:(nrow(d))) { tmp &lt;- d$vec_img[[i]] names(tmp) &lt;- cols res &lt;- res %&gt;% bind_rows(tmp) } res &lt;- res %&gt;% mutate(label = as.factor(d$label)) toc() return(res) } # 3300秒くらいかかる # res_51 &lt;- make_data(data,1,51) # 一度読み込んだものをrdsに保存しておいた res_51 &lt;- read_rds(here(&quot;data/res_51.rds&quot;)) res_2 &lt;- res_51 %&gt;% filter(label %in% s[1:2]) %&gt;% mutate(label = as.factor(label)) res_10 &lt;- res_51 %&gt;% filter(label %in% s[1:10]) %&gt;% mutate(label = as.factor(label)) res_30 &lt;- res_51 %&gt;% filter(label %in% s[1:30]) %&gt;% mutate(label = as.factor(label)) 4.7 モデリング 4.7.1 データをtrain/testに80%/20%で分割する set.seed(7777) splits &lt;- res_2 %&gt;% initial_split(prop = 0.8, strata = label) train &lt;- training(splits) test &lt;- testing(splits) 4.7.2 tidymodelsの準備 target_var &lt;- sym(&quot;label&quot;) # set target_var, sym means symbol mode &lt;- &quot;classification&quot; # set estimate type formula &lt;- expr(formula(!!target_var ~ .)) # set formura # set recipes rec &lt;- train %&gt;% recipe(formula = formula) rec_preped &lt;- prep(rec) 4.7.3 random forestとxgboostのモデルを定義 # random forest model_rf &lt;- rand_forest() %&gt;% set_engine(&quot;ranger&quot;) %&gt;% set_mode(mode) #boosted trees model_xgb &lt;- boost_tree() %&gt;% set_engine(&quot;xgboost&quot;) %&gt;% set_mode(mode) model_list &lt;- list(rf = model_rf, xgb = model_xgb) flow_list &lt;- workflow() %&gt;% add_recipe(rec) flow_list &lt;- map(.x = model_list, ~add_model(x = flow_list, spec = .x)) 4.8 計測 4.8.1 計測する（２文字） rfとxgboostそれぞれ50回ずつfitさせる時間を計測する baked_train &lt;- bake(rec,train) # random forest time_rf_2 &lt;- microbenchmark( fit_rf &lt;- fit(flow_list$rf, data = baked_train), times = 2 ) # xgboost time_xgb_2 &lt;- microbenchmark( fit_xgb &lt;- fit(flow_list$xgb, data = baked_train), times = 2 ) 4.8.2 計測結果（２文字） bind_rows(time_rf_2, time_xgb_2) ## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector ## Unit: seconds ## expr min lq mean median uq max neval ## fit_rf &lt;- fit(flow_list$rf, data = baked_train) 1.207564 1.207564 1.350436 1.350436 1.493308 1.493308 2 ## fit_xgb &lt;- fit(flow_list$xgb, data = baked_train) 1.202549 1.202549 1.207039 1.207039 1.211529 1.211529 2 my_plot &lt;- function(time_rf, time_xgb, bins=20){ tibble(rf = time_rf$time/1e+09, xgb = time_xgb$time/1e+09) %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(value)) + geom_histogram(bins = bins) + facet_wrap(vars(name), ncol = 1) } my_plot(time_rf_2, time_xgb_2, bins = 20) 4.8.3 予測結果（２文字） my_predict &lt;- function(){ fit_rf &lt;- fit(flow_list$rf, data = bake(rec, test)) pred_rf &lt;- predict(fit_rf, new_data = bake(rec, test)) pred_conf_rf &lt;- caret::confusionMatrix(pred_rf$.pred_class, test$label) fit_xgb &lt;- fit(flow_list$xgb, data = bake(rec, test)) pred_xgb &lt;- predict(fit_xgb, new_data = bake(rec, test)) pred_conf_xgb &lt;- caret::confusionMatrix(pred_xgb$.pred_class, test$label) return(list(rf = pred_conf_rf$table, xgb= pred_conf_xgb$table)) } my_predict() ## $rf ## Reference ## Prediction あ い ## あ 23 0 ## い 0 23 ## ## $xgb ## Reference ## Prediction あ い ## あ 23 0 ## い 0 23 4.8.4 計測する（１０文字） rfとxgboostそれぞれ50回ずつfitさせる時間を計測する。 データの作成に4分くらいかかる。 fitには全部で11分くらい。 # set recipes rec &lt;- train %&gt;% recipe(formula = formula) rec_preped &lt;- prep(rec) flow_list &lt;- workflow() %&gt;% add_recipe(rec) flow_list &lt;- map(.x = model_list, ~add_model(x = flow_list, spec = .x)) set.seed(7777) splits &lt;- res_10 %&gt;% initial_split(prop = 0.8, strata = label) ## Warning: Too little data to stratify. Unstratified resampling will be used. train &lt;- training(splits) test &lt;- testing(splits) baked_train &lt;- bake(rec,train) # random forest time_rf_10 &lt;- microbenchmark( fit_rf &lt;- fit(flow_list$rf, data = baked_train), times = 50 ) # xgboost time_xgb_10 &lt;- microbenchmark( fit_xgb &lt;- fit(flow_list$xgb, data = baked_train), times = 50 ) 4.8.5 計測結果（１０文字） bind_rows(time_rf_10, time_xgb_10) ## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector ## Unit: seconds ## expr min lq mean median uq max neval ## fit_rf &lt;- fit(flow_list$rf, data = baked_train) 3.02797 3.053799 3.313087 3.063390 3.095673 15.011433 50 ## fit_xgb &lt;- fit(flow_list$xgb, data = baked_train) 8.13080 8.285678 8.391799 8.312129 8.454143 9.271326 50 my_plot(time_rf_10, time_xgb_10, bins = 30) 4.8.6 予測結果（１０文字） my_predict() ## $rf ## Reference ## Prediction あ い う え お か き く け こ ## あ 25 0 0 0 0 0 0 0 0 0 ## い 0 25 0 0 0 0 0 0 0 0 ## う 0 0 15 0 0 0 0 0 0 0 ## え 0 0 0 23 0 0 0 0 0 0 ## お 0 0 0 0 19 0 0 0 0 0 ## か 0 0 0 0 0 21 0 0 0 0 ## き 0 0 0 0 0 0 30 0 0 0 ## く 0 0 0 0 0 0 0 26 0 0 ## け 0 0 0 0 0 0 0 0 23 0 ## こ 0 0 0 0 0 0 0 0 0 30 ## ## $xgb ## Reference ## Prediction あ い う え お か き く け こ ## あ 25 0 0 0 0 0 0 0 0 0 ## い 0 25 0 0 0 0 0 0 0 0 ## う 0 0 15 0 0 0 0 0 0 0 ## え 0 0 0 23 0 0 0 0 0 0 ## お 0 0 0 0 19 0 0 0 0 0 ## か 0 0 0 0 0 21 0 0 0 0 ## き 0 0 0 0 0 0 30 0 0 0 ## く 0 0 0 0 0 0 0 26 0 0 ## け 0 0 0 0 0 0 0 0 23 0 ## こ 0 0 0 0 0 0 0 0 0 30 4.8.7 計測する（３０文字） rfとxgboostそれぞれ50回ずつfitさせる時間を計測する。 fitには全部で分くらい。 # set recipes rec &lt;- train %&gt;% recipe(formula = formula) rec_preped &lt;- prep(rec) flow_list &lt;- workflow() %&gt;% add_recipe(rec) flow_list &lt;- map(.x = model_list, ~add_model(x = flow_list, spec = .x)) set.seed(7777) splits &lt;- res_30 %&gt;% initial_split(prop = 0.8, strata = label) ## Warning: Too little data to stratify. Unstratified resampling will be used. train &lt;- training(splits) test &lt;- testing(splits) baked_train &lt;- bake(rec,train) # random forest time_rf_30 &lt;- microbenchmark( fit_rf &lt;- fit(flow_list$rf, data = baked_train), times = 50 ) # xgboost time_xgb_30 &lt;- microbenchmark( fit_xgb &lt;- fit(flow_list$xgb, data = baked_train), times = 50 ) 4.8.8 計測結果（３０文字） bind_rows(time_rf_30, time_xgb_30) ## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into ## character vector ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into ## character vector ## Unit: seconds ## expr min lq mean median ## fit_rf &lt;- fit(flow_list$rf, data = baked_train) 12.92101 13.17005 14.75011 14.36868 ## fit_xgb &lt;- fit(flow_list$xgb, data = baked_train) 58.12537 60.32577 68.51813 64.00283 ## uq max neval ## 15.53056 20.77089 50 ## 68.39914 155.76152 50 my_plot(time_rf_30, time_xgb_30, bins = 30) 4.8.9 予測結果（３０文字） my_predict() ## $rf ## Reference ## Prediction あ い う え お か き く け こ さ し す せ そ た ち つ て と な に ぬ ね の ## あ 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## い 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## う 0 0 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## え 0 0 0 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## お 0 0 0 0 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## か 0 0 0 0 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## き 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## く 0 0 0 0 0 0 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## け 0 0 0 0 0 0 0 0 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## こ 0 0 0 0 0 0 0 0 0 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## さ 0 0 0 0 0 0 0 0 0 0 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## し 0 0 0 0 0 0 0 0 0 0 0 16 0 0 0 0 0 0 0 0 0 0 0 0 0 ## す 0 0 0 0 0 0 0 0 0 0 0 0 20 0 0 0 0 0 0 0 0 0 0 0 0 ## せ 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 0 0 ## そ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 0 0 ## た 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 ## ち 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 ## つ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 23 0 0 0 0 0 0 0 ## て 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 0 0 0 0 0 0 ## と 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 ## な 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 20 0 0 0 0 ## に 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 ## ぬ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 19 0 0 ## ね 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 ## の 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 21 ## は 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ひ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ふ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## へ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ほ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## Reference ## Prediction は ひ ふ へ ほ ## あ 0 0 0 0 0 ## い 0 0 0 0 0 ## う 0 0 0 0 0 ## え 0 0 0 0 0 ## お 0 0 0 0 0 ## か 0 0 0 0 0 ## き 0 0 0 0 0 ## く 0 0 0 0 0 ## け 0 0 0 0 0 ## こ 0 0 0 0 0 ## さ 0 0 0 0 0 ## し 0 0 0 0 0 ## す 0 0 0 0 0 ## せ 0 0 0 0 0 ## そ 0 0 0 0 0 ## た 0 0 0 0 0 ## ち 0 0 0 0 0 ## つ 0 0 0 0 0 ## て 0 0 0 0 0 ## と 0 0 0 0 0 ## な 0 0 0 0 0 ## に 0 0 0 0 0 ## ぬ 0 0 0 0 0 ## ね 0 0 0 0 0 ## の 0 0 0 0 0 ## は 26 0 0 0 0 ## ひ 0 31 0 0 0 ## ふ 0 0 25 0 0 ## へ 0 0 0 22 0 ## ほ 0 0 0 0 24 ## ## $xgb ## Reference ## Prediction あ い う え お か き く け こ さ し す せ そ た ち つ て と な に ぬ ね の ## あ 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## い 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## う 0 0 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## え 0 0 0 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## お 0 0 0 0 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## か 0 0 0 0 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## き 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## く 0 0 0 0 0 0 0 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## け 0 0 0 0 0 0 0 0 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## こ 0 0 0 0 0 0 0 0 0 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## さ 0 0 0 0 0 0 0 0 0 0 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## し 0 0 0 0 0 0 0 0 0 0 0 16 0 0 0 0 0 0 0 0 0 0 0 0 0 ## す 0 0 0 0 0 0 0 0 0 0 0 0 20 0 0 0 0 0 0 0 0 0 0 0 0 ## せ 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 0 0 ## そ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 0 0 ## た 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 ## ち 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 0 0 ## つ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 23 0 0 0 0 0 0 0 ## て 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 0 0 0 0 0 0 ## と 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 ## な 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 20 0 0 0 0 ## に 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 0 0 ## ぬ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 19 0 0 ## ね 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 24 0 ## の 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 21 ## は 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ひ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ふ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## へ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## ほ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## Reference ## Prediction は ひ ふ へ ほ ## あ 0 0 0 0 0 ## い 0 0 0 0 0 ## う 0 0 0 0 0 ## え 0 0 0 0 0 ## お 0 0 0 0 0 ## か 0 0 0 0 0 ## き 0 0 0 0 0 ## く 0 0 0 0 0 ## け 0 0 0 0 0 ## こ 0 0 0 0 0 ## さ 0 0 0 0 0 ## し 0 0 0 0 0 ## す 0 0 0 0 0 ## せ 0 0 0 0 0 ## そ 0 0 0 0 0 ## た 0 0 0 0 0 ## ち 0 0 0 0 0 ## つ 0 0 0 0 0 ## て 0 0 0 0 0 ## と 0 0 0 0 0 ## な 0 0 0 0 0 ## に 0 0 0 0 0 ## ぬ 0 0 0 0 0 ## ね 0 0 0 0 0 ## の 0 0 0 0 0 ## は 26 0 0 0 0 ## ひ 0 31 0 0 0 ## ふ 0 0 25 0 0 ## へ 0 0 0 22 0 ## ほ 0 0 0 0 24 "]
]
